{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are five model sizes, four with English-only versions, offering speed and accuracy tradeoffs. Below are the names of the available models and their approximate memory requirements and inference speed relative to the large model; actual speed may vary depending on many factors including the available hardware.\n",
    "\n",
    "|  Size  | Parameters | English-only model | Multilingual model | Required VRAM | Relative speed |\n",
    "|:------:|:----------:|:------------------:|:------------------:|:-------------:|:--------------:|\n",
    "|  tiny  |    39 M    |     `tiny.en`      |       `tiny`       |     ~1 GB     |      ~32x      |\n",
    "|  base  |    74 M    |     `base.en`      |       `base`       |     ~1 GB     |      ~16x      |\n",
    "| small  |   244 M    |     `small.en`     |      `small`       |     ~2 GB     |      ~6x       |\n",
    "| medium |   769 M    |    `medium.en`     |      `medium`      |     ~5 GB     |      ~2x       |\n",
    "| large  |   1550 M   |        N/A         |      `large`       |    ~10 GB     |       1x       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If tested, please provide your filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = 'ervin_speech.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There's no point standing around will only be showered by more boulders. Ready your horses on the double! Be honest, are all of us riding to our deaths? Yes, we are. And since we're dying anyway, you're saying that it's better? If we have this time riding... I am. But wait, if we'll die anyway, then who cares what we do? We could just this obey your own.\n"
     ]
    }
   ],
   "source": [
    "# 30 seconds -> 7 seconds\n",
    "model = whisper.load_model('base.en')\n",
    "result = model.transcribe(audio_path, fp16 = False)\n",
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There's no point standing around. We'll only be showered by more boulders. Ready your horses on the double! Be honest. Are all of us... riding to our deaths? Yes, we are. And since we're dying anyway, you're saying that it's better? If we at least die fighting... I am. But wait. If we'll die anyway, then who cares what we do? We could just disobey your horses.\n"
     ]
    }
   ],
   "source": [
    "# 30 seconds -> 18 seconds\n",
    "model = whisper.load_model('small.en')\n",
    "result = model.transcribe(audio_path, fp16 = False)\n",
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There's no point standing around. We'll only be showered by more boulders. Ready your horses on the double! Be honest. Are all of us riding to our deaths? Yes, we are. And since we're dying anyway, you're saying that it's better? If we at least die fighting? I am. But wait. If we'll die anyway, then who cares what we do? We could just disobey your own death.\n"
     ]
    }
   ],
   "source": [
    "# 30 seconds -> 51 seconds\n",
    "model = whisper.load_model('medium.en')\n",
    "result = model.transcribe(audio_path, fp16 = False)\n",
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There's no point standing around. We'll only be showered by more boulders. Ready your horses on the double! Be honest. Are all of us... ...riding to our deaths? Yes, we are. And since we're dying anyway, you're saying that it's better... ...if we at least stop fighting? I am. But wait... If we'll die anyway, then who cares what we do? We could just disobey your orders.\n"
     ]
    }
   ],
   "source": [
    "# 30 seconds -> 183 seconds\n",
    "model = whisper.load_model('large')\n",
    "result = model.transcribe(audio_path, fp16 = False)\n",
    "print(result['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
